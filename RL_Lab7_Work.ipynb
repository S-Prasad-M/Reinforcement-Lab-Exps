{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f58abac6",
   "metadata": {},
   "source": [
    "<center>\n",
    "\n",
    "# **22AIE401 - Reinforcement Learning**  \n",
    "# **Lab 7**  \n",
    "\n",
    "</center>\n",
    "\n",
    "### Team Members:\n",
    "- Guruprasath M R - AIE22015  \n",
    "- Rudraksh Mohanty - AIE22046  \n",
    "- Shree Prasad M - AIE22050  \n",
    "- Tharun Kaarthik G K - AIE22062  \n",
    "\n",
    "---\n",
    "\n",
    "### Objective:\n",
    "Smart Drone Navigation using Dyna-Q \n",
    "To implement and understand the Dyna-Q reinforcement learning algorithm in a partially known  environment, enabling a delivery drone to learn the optimal path to its target while avoiding obstacles. \n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "### Problem Statement:\n",
    "A delivery drone operates in an 8×8 urban grid. Its goal is to deliver a package from the warehouse at (0,0) to a drop point at (7,7). However, certain grid cells represent buildings/obstacles, and movement into them incurs a penalty. The drone must learn to reach the target location in the shortest path with minimal penalty using the Dyna-Q algorithm. \n",
    " \n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "## Original Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c71e470c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sudo is disabled on this machine. To enable it, go to the \u001b]8;;ms-settings:developers\u001b\\Developer Settings page\u001b]8;;\u001b\\ in the Settings app\n",
      "Sudo is disabled on this machine. To enable it, go to the \u001b]8;;ms-settings:developers\u001b\\Developer Settings page\u001b]8;;\u001b\\ in the Settings app\n",
      "Sudo is disabled on this machine. To enable it, go to the \u001b]8;;ms-settings:developers\u001b\\Developer Settings page\u001b]8;;\u001b\\ in the Settings app\n"
     ]
    }
   ],
   "source": [
    "!sudo apt update\n",
    "!sudo apt install ffmpeg\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "886a0a17",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] The system cannot find the file specified",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 109\u001b[0m\n\u001b[0;32m    107\u001b[0m save_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlab7_dyna_q_drone_navigation.mp4\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    108\u001b[0m writer \u001b[38;5;241m=\u001b[39m FFMpegWriter(fps\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m, metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mdict\u001b[39m(artist\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRL Lab 7\u001b[39m\u001b[38;5;124m'\u001b[39m), bitrate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1800\u001b[39m) \n\u001b[1;32m--> 109\u001b[0m \u001b[43manim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43msave_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mwriter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwriter\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m    110\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m✅ Drone navigation video saved as \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msave_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\spras\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\animation.py:1063\u001b[0m, in \u001b[0;36mAnimation.save\u001b[1;34m(self, filename, writer, fps, dpi, codec, bitrate, extra_args, metadata, extra_anim, savefig_kwargs, progress_callback)\u001b[0m\n\u001b[0;32m   1057\u001b[0m     _log\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDisabling savefig.bbox = \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtight\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, as it may cause \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1058\u001b[0m               \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mframe size to vary, which is inappropriate for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1059\u001b[0m               \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manimation.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1060\u001b[0m \u001b[38;5;66;03m# canvas._is_saving = True makes the draw_event animation-starting\u001b[39;00m\n\u001b[0;32m   1061\u001b[0m \u001b[38;5;66;03m# callback a no-op; canvas.manager = None prevents resizing the GUI\u001b[39;00m\n\u001b[0;32m   1062\u001b[0m \u001b[38;5;66;03m# widget (both are likewise done in savefig()).\u001b[39;00m\n\u001b[1;32m-> 1063\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrc_context\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msavefig.bbox\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m   1064\u001b[0m \u001b[43m     \u001b[49m\u001b[43mwriter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msaving\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdpi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m\\\u001b[49m\n\u001b[0;32m   1065\u001b[0m \u001b[43m     \u001b[49m\u001b[43mcbook\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_setattr_cm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1066\u001b[0m \u001b[43m                       \u001b[49m\u001b[43m_is_saving\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmanager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1067\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43manim\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mall_anim\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m   1068\u001b[0m \u001b[43m        \u001b[49m\u001b[43manim\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_init_draw\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Clear the initial frame\u001b[39;49;00m\n",
      "File \u001b[1;32mc:\\Users\\spras\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\contextlib.py:137\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[0;32m    136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 137\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgen)\n\u001b[0;32m    138\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[0;32m    139\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\spras\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\animation.py:229\u001b[0m, in \u001b[0;36mAbstractMovieWriter.saving\u001b[1;34m(self, fig, outfile, dpi, *args, **kwargs)\u001b[0m\n\u001b[0;32m    223\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;124;03mContext manager to facilitate writing the movie file.\u001b[39;00m\n\u001b[0;32m    225\u001b[0m \n\u001b[0;32m    226\u001b[0m \u001b[38;5;124;03m``*args, **kw`` are any parameters that should be passed to `setup`.\u001b[39;00m\n\u001b[0;32m    227\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;66;03m# This particular sequence is what contextlib.contextmanager wants\u001b[39;00m\n\u001b[1;32m--> 229\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdpi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    230\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    231\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\spras\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\animation.py:318\u001b[0m, in \u001b[0;36mMovieWriter.setup\u001b[1;34m(self, fig, outfile, dpi)\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_w, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_adjust_frame_size()\n\u001b[0;32m    316\u001b[0m \u001b[38;5;66;03m# Run here so that grab_frame() can write the data to a pipe. This\u001b[39;00m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;66;03m# eliminates the need for temp files.\u001b[39;00m\n\u001b[1;32m--> 318\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\spras\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\matplotlib\\animation.py:328\u001b[0m, in \u001b[0;36mMovieWriter._run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    325\u001b[0m _log\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMovieWriter._run: running command: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m    326\u001b[0m           cbook\u001b[38;5;241m.\u001b[39m_pformat_subprocess(command))\n\u001b[0;32m    327\u001b[0m PIPE \u001b[38;5;241m=\u001b[39m subprocess\u001b[38;5;241m.\u001b[39mPIPE\n\u001b[1;32m--> 328\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_proc \u001b[38;5;241m=\u001b[39m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    329\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstdin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstderr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    330\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubprocess_creation_flags\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\spras\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\subprocess.py:1024\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[0m\n\u001b[0;32m   1020\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_mode:\n\u001b[0;32m   1021\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[0;32m   1022\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m-> 1024\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1025\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1026\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1027\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1028\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1029\u001b[0m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1030\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1031\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1032\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprocess_group\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1033\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m   1034\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[0;32m   1035\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdin, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr)):\n",
      "File \u001b[1;32mc:\\Users\\spras\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\subprocess.py:1493\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session, unused_process_group)\u001b[0m\n\u001b[0;32m   1491\u001b[0m \u001b[38;5;66;03m# Start the process\u001b[39;00m\n\u001b[0;32m   1492\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1493\u001b[0m     hp, ht, pid, tid \u001b[38;5;241m=\u001b[39m \u001b[43m_winapi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCreateProcess\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1494\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;66;43;03m# no special security\u001b[39;49;00m\n\u001b[0;32m   1495\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1496\u001b[0m \u001b[43m                             \u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1497\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1498\u001b[0m \u001b[43m                             \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1499\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1500\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1501\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1502\u001b[0m     \u001b[38;5;66;03m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m     \u001b[38;5;66;03m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1506\u001b[0m     \u001b[38;5;66;03m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[0;32m   1507\u001b[0m     \u001b[38;5;66;03m# ReadFile will hang.\u001b[39;00m\n\u001b[0;32m   1508\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_pipe_fds(p2cread, p2cwrite,\n\u001b[0;32m   1509\u001b[0m                          c2pread, c2pwrite,\n\u001b[0;32m   1510\u001b[0m                          errread, errwrite)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.patches as patches \n",
    "from matplotlib.animation import FuncAnimation, FFMpegWriter \n",
    "import random \n",
    "from collections import defaultdict \n",
    "\n",
    "# ---------------------- Environment Setup ---------------------- #\n",
    "GRID_SIZE = 8\n",
    "ACTIONS = ['U', 'D', 'L', 'R'] \n",
    "ACTION_MAP = {'U': (-1, 0), 'D': (1, 0), 'L': (0, -1), 'R': (0, 1)} \n",
    "GOAL = (7, 7) \n",
    "OBSTACLES = {(3, 3), (4, 4), (2, 5), (6, 2)} \n",
    "REWARD_GOAL = 100\n",
    "REWARD_STEP = -1\n",
    "REWARD_OBSTACLE = -10\n",
    "EPISODES = 300\n",
    "MAX_STEPS = 50\n",
    "EPSILON = 0.1\n",
    "ALPHA = 0.1\n",
    "GAMMA = 0.95\n",
    "PLANNING_STEPS = 10\n",
    "Q = defaultdict(lambda: {a: 0 for a in ACTIONS}) \n",
    "model = {} \n",
    "\n",
    "def is_valid(pos): \n",
    "    return 0 <= pos[0] < GRID_SIZE and 0 <= pos[1] < GRID_SIZE and pos not in OBSTACLES \n",
    "\n",
    "def step(state, action): \n",
    "    dx, dy = ACTION_MAP[action] \n",
    "    next_state = (state[0] + dx, state[1] + dy) \n",
    "    if not is_valid(next_state): \n",
    "        return state, REWARD_OBSTACLE \n",
    "    if next_state == GOAL: \n",
    "        return next_state, REWARD_GOAL \n",
    "    return next_state, REWARD_STEP \n",
    "\n",
    "def select_action(state): \n",
    "    if np.random.rand() < EPSILON: \n",
    "        return random.choice(ACTIONS) \n",
    "    return max(Q[state], key=Q[state].get) \n",
    "\n",
    "# ---------------------- Dyna-Q Training ---------------------- #\n",
    "for ep in range(EPISODES): \n",
    "    state = (0, 0) \n",
    "    for _ in range(MAX_STEPS): \n",
    "        action = select_action(state) \n",
    "        next_state, reward = step(state, action) \n",
    "        # Q-learning update\n",
    "        best_next = max(Q[next_state], key=Q[next_state].get) \n",
    "        Q[state][action] += ALPHA * (reward + GAMMA * Q[next_state][best_next] - Q[state][action]) \n",
    "        # Model learning\n",
    "        model[(state, action)] = (next_state, reward) \n",
    "        # Planning updates\n",
    "        for _ in range(PLANNING_STEPS): \n",
    "            s, a = random.choice(list(model.keys())) \n",
    "            s_, r = model[(s, a)] \n",
    "            best_s_ = max(Q[s_], key=Q[s_].get) \n",
    "            Q[s][a] += ALPHA * (r + GAMMA * Q[s_][best_s_] - Q[s][a]) \n",
    "        if next_state == GOAL: \n",
    "            break\n",
    "        state = next_state \n",
    "\n",
    "# ---------------------- Extract Path ---------------------- #\n",
    "path = [(0, 0)] \n",
    "state = (0, 0) \n",
    "for _ in range(30): \n",
    "    action = select_action(state) \n",
    "    state, _ = step(state, action) \n",
    "    path.append(state) \n",
    "    if state == GOAL: \n",
    "        break\n",
    "\n",
    "# ---------------------- Visualization Setup ---------------------- #\n",
    "fig, ax = plt.subplots(figsize=(6, 6)) \n",
    "drone_patch = patches.Circle((0.5, 0.5), 0.3, color='blue') \n",
    "\n",
    "def init(): \n",
    "    ax.clear() \n",
    "    ax.set_xlim(0, GRID_SIZE) \n",
    "    ax.set_ylim(0, GRID_SIZE) \n",
    "    ax.set_xticks(np.arange(GRID_SIZE + 1)) \n",
    "    ax.set_yticks(np.arange(GRID_SIZE + 1)) \n",
    "    ax.grid(True) \n",
    "    for i in range(GRID_SIZE): \n",
    "        for j in range(GRID_SIZE): \n",
    "            cell = (i, j) \n",
    "            color = 'white'\n",
    "            if cell in OBSTACLES: \n",
    "                color = 'black'\n",
    "            elif cell == GOAL: \n",
    "                color = 'gold'\n",
    "            rect = patches.Rectangle((j, GRID_SIZE - i - 1), 1, 1, facecolor=color) \n",
    "            ax.add_patch(rect) \n",
    "    return [] \n",
    "\n",
    "def update(frame): \n",
    "    init() \n",
    "    rx, ry = path[frame] \n",
    "    drone_patch.center = (ry + 0.5, GRID_SIZE - rx - 0.5) \n",
    "    ax.add_patch(drone_patch) \n",
    "    return [drone_patch] \n",
    "\n",
    "anim = FuncAnimation(fig, update, frames=len(path), init_func=init, blit=True) \n",
    "\n",
    "# ---------------------- Save to Video ---------------------- #\n",
    "save_path = \"lab7_dyna_q_drone_navigation.mp4\"\n",
    "writer = FFMpegWriter(fps=2, metadata=dict(artist='RL Lab 7'), bitrate=1800) \n",
    "anim.save(save_path, writer=writer) \n",
    "print(f\"✅ Drone navigation video saved as {save_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed501a5",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "\n",
    "The drone must pick up a payload at a pickup zone and then deliver it to any of multiple delivery\n",
    "points. Add pickup_zone = (2,2) with no reward. Agent must first visit pickup, then reach one of multiple delivery goals [(3,9), (8,4), (9,9)] to finish the mission. Add a has_payload flag in the environment state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1570f2f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pickup_zone = (2, 2)\n",
    "delivery_goals = [(3, 7), (7, 4), (7, 7)]  # Adjusted to fit 8x8 grid\n",
    "\n",
    "class DroneEnv:\n",
    "    def __init__(self):\n",
    "        self.grid_size = GRID_SIZE\n",
    "        self.obstacles = OBSTACLES\n",
    "        self.pickup_zone = pickup_zone\n",
    "        self.delivery_goals = delivery_goals\n",
    "        self.reset()\n",
    "    def reset(self):\n",
    "        self.state = (0, 0)\n",
    "        self.has_payload = False\n",
    "        return self.state, self.has_payload\n",
    "    def is_valid(self, pos):\n",
    "        return 0 <= pos[0] < self.grid_size and 0 <= pos[1] < self.grid_size and pos not in self.obstacles\n",
    "    def step(self, state, has_payload, action):\n",
    "        dx, dy = ACTION_MAP[action]\n",
    "        next_state = (state[0] + dx, state[1] + dy)\n",
    "        reward = REWARD_STEP\n",
    "        done = False\n",
    "        if not self.is_valid(next_state):\n",
    "            reward = REWARD_OBSTACLE\n",
    "            next_state = state\n",
    "        elif not has_payload and next_state == self.pickup_zone:\n",
    "            has_payload = True\n",
    "            reward = 0\n",
    "        elif has_payload and next_state in self.delivery_goals:\n",
    "            reward = REWARD_GOAL\n",
    "            done = True\n",
    "        return next_state, has_payload, reward, done\n",
    "\n",
    "env = DroneEnv()\n",
    "Q = defaultdict(lambda: {a: 0 for a in ACTIONS})\n",
    "model = {}\n",
    "\n",
    "for ep in range(EPISODES):\n",
    "    state, has_payload = env.reset()\n",
    "    for _ in range(MAX_STEPS):\n",
    "        action = select_action((state, has_payload))\n",
    "        next_state, next_payload, reward, done = env.step(state, has_payload, action)\n",
    "        best_next = max(Q[(next_state, next_payload)], key=Q[(next_state, next_payload)].get)\n",
    "        Q[(state, has_payload)][action] += ALPHA * (reward + GAMMA * Q[(next_state, next_payload)][best_next] - Q[(state, has_payload)][action])\n",
    "        model[((state, has_payload), action)] = (next_state, next_payload, reward)\n",
    "        for _ in range(PLANNING_STEPS):\n",
    "            (s, p), a = random.choice(list(model.keys()))\n",
    "            s_, p_, r = model[((s, p), a)]\n",
    "            best_s_ = max(Q[(s_, p_)], key=Q[(s_, p_)].get)\n",
    "            Q[(s, p)][a] += ALPHA * (r + GAMMA * Q[(s_, p_)][best_s_] - Q[(s, p)][a])\n",
    "        if done:\n",
    "            break\n",
    "        state, has_payload = next_state, next_payload\n",
    "\n",
    "# After training, extract and print the path for Task 1\n",
    "path = []\n",
    "state, has_payload = env.reset()\n",
    "for _ in range(50):\n",
    "    action = select_action((state, has_payload))\n",
    "    next_state, next_payload, reward, done = env.step(state, has_payload, action)\n",
    "    path.append((state, action, next_state, has_payload, reward))\n",
    "    if done:\n",
    "        break\n",
    "    state, has_payload = next_state, next_payload\n",
    "print(\"Task 1: Drone path (state, action, next_state, has_payload, reward):\")\n",
    "for step in path:\n",
    "    print(step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f2a5a8c",
   "metadata": {},
   "source": [
    "## Task 2\n",
    "\n",
    "Migrate code to use function approximation for Q-value estimation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d503df4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class QNet(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim):\n",
    "        super(QNet, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(state_dim, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, action_dim)\n",
    "        )\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "def state_to_tensor(state, has_payload):\n",
    "    return torch.tensor([state[0], state[1], int(has_payload)], dtype=torch.float32)\n",
    "\n",
    "action_to_idx = {a: i for i, a in enumerate(ACTIONS)}\n",
    "idx_to_action = {i: a for a, i in action_to_idx.items()}\n",
    "\n",
    "qnet = QNet(3, len(ACTIONS))\n",
    "optimizer = optim.Adam(qnet.parameters(), lr=0.01)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "# Track and print total reward per episode for Task 2\n",
    "rewards_per_episode = []\n",
    "for ep in range(EPISODES):\n",
    "    state, has_payload = env.reset()\n",
    "    total_reward = 0\n",
    "    for _ in range(MAX_STEPS):\n",
    "        s_tensor = state_to_tensor(state, has_payload)\n",
    "        q_values = qnet(s_tensor)\n",
    "        if np.random.rand() < EPSILON:\n",
    "            action_idx = np.random.choice(len(ACTIONS))\n",
    "        else:\n",
    "            action_idx = torch.argmax(q_values).item()\n",
    "        action = idx_to_action[action_idx]\n",
    "        next_state, next_payload, reward, done = env.step(state, has_payload, action)\n",
    "        next_s_tensor = state_to_tensor(next_state, next_payload)\n",
    "        next_q_values = qnet(next_s_tensor)\n",
    "        target = q_values.clone().detach()\n",
    "        target[action_idx] = reward + GAMMA * torch.max(next_q_values).item()\n",
    "        loss = loss_fn(q_values, target)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_reward += reward\n",
    "        if done:\n",
    "            break\n",
    "        state, has_payload = next_state, next_payload\n",
    "    rewards_per_episode.append(total_reward)\n",
    "print(\"Task 2: Total reward per episode:\")\n",
    "print(rewards_per_episode)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
